---
Title: "Try Using Github Action In The CICD Workflow"
Date: 2022-02-12T13:15:32+11:00
Draft: true
Summary: We had plans to deploy CICD before and have tried using AWS CodePipeline to deploy simple CD. However, we have never used Github Action before. This time, we took the opportunity to try it out while developing a new project using Rust.
---

We had plans to deploy CICD before and have tried using AWS CodePipeline to deploy simple CD. However, we have never used Github Action before. This time, we took the opportunity to try it out while developing a new project using Rust.

The initial goal was to use GitHub Actions to implement automated testing. Once the tests pass, a Docker image is built and pushed to AWS ECR. Then, the image is published to a Kubernetes cluster through CodePipeline. The entire process is clear, with the CD part, which I have done before, so the main area I need to learn about is the CI part. For the CD part, I plan to use Terraform to code the infrastructure needed for easy management and maintenance in the future. Although the entire process does not seem difficult, I did encounter some pitfalls and also learned or reviewed some important points for CI/CD. 

First, why choose GitHub Actions as the CI tool? I have seen many open-source projects using GitHub Actions before, and have also read some blogs about migrating from Bitbucket to GitHub Actions. The most attractive feature is the powerful open-source marketplace for actions, which greatly reduces the workload of development. The dependent bot is also very convenient, and many open-source projects are using it. In addition, some security checks, including the application of machine learning, make me feel that GitHub has great potential in DevOps. Even a proprietary term, GitOps, has emerged, and we can no longer ignore the important role that GitHub plays in DevOps. Although theoretically, I can implement all of this on CodeBuild, it is almost unimaginable to achieve the same effect with the same investment. Moreover, our company has purchased GitHub Enterprise services, which provide 3000 minutes of computing time per month, so it is waste not to use it.

By reading the documentation of GitHub Workflow, I have a rough understanding of how to use GitHub Action, especially the best practices for security. GitHub Action is mostly fully codified and saved in the .github workflow of the project. Its functionality is very powerful and flexible, but if used incorrectly, there may be security risks such as key leakage. One of them is not to use third-party actions easily. If you want to use them, you should also read their code thoroughly, use appropriate tags to fix the version, or fork their repo. Also, user-controlled parameters need to be controlled to prevent injection attacks. In addition to security, there are also some optimizations, such as using cache to speed up deployment and reduce the running time of GitHub Action. GitHub Action's syntax conveniently supports multi-platform testing. Because this test application only runs on Linux, I considered the Linux situation this time. After the test is completed, it needs to be uploaded to AWS ECR, which requires corresponding permissions. For this, I used the secret in the repo to provide the relevant AWS secret key, so that only this repo can access this secret, and this AWS user only has the corresponding permission to push images to the ECR repo. This is both convenient and secure.

After completing the deployment of Github Action and pushing to AWS ECR, the next step is to configure AWS CodePipeline. I previously configured one using the web console provided by AWS, but it wasn't code-based. This time, I used Terraform to deploy the CD pipeline, but ran into several problems, mainly related to permissions. In CodePipeline, I mainly needed to retrieve the deployment.yaml file required by Kubernetes from S3 and then use the kb apply method to update the deployment in Kubernetes. CodePipeline mainly requires two permissions: permission to retrieve objects from S3 using getobject and permission to connect to Kubernetes and send the apply command. For the first permission, in addition to giving CodeBuild the minimum required IAM privileges, relevant policies must be configured for the S3 bucket; otherwise, an access denied error will occur. For the second permission, in addition to configuring IAM, the permission binding of the corresponding IAM role must be added to the ConfigMap of Kubernetes (system master).

After completing these steps, the entire testing and publishing process of CICD is basically connected. The next step is to add more features, starting with adding versioning. To achieve this goal, I roughly thought of two methods. One is to tag the commit locally when committing and generate the relevant deployment.yaml file together, so that when publishing, you only need to retrieve the yaml file on Github. This step requires giving CodePipeline permission to access Github. The second method is to dynamically generate the relevant deployment.yaml during Github Action and upload it to S3, and retrieve it directly from S3 when publishing. This method requires adding permissions for Github Action to upload files to S3. After weighing the options, I decided to use the second method, mainly because it is more flexible and easy to implement (there are many open source Github Actions), and the version-related data does not feel related to the code but more to the deployment. Once this method was chosen, I began to look for a Github Action to upload to S3, and tried one with the most stars, but it failed due to access denied. After looking at the issue, I found that someone had encountered a similar problem but there was no confirmed solution. I tested it locally and found that the same logic and permission worked successfully. However, once I used the Github Action, whether I simulated Github Action locally using "act" or uploaded it directly to Github, it failed due to access denied. So, it was very strange. Finally, I used another Github Action with the same permission and successfully uploaded it. This Github Action used docker+python version of AWS SDK, which is more flexible to use.

Finally, we need to add the functionality of alerts. The idea is to send a notification to the corresponding channel via Slack API after the deployment is completed. This part is straightforward and there is nothing much to say. Then, there is a plan to add a manual review process. Currently, because it is still in the testing phase, the application is directly deployed to the staging server. However, for the production phase, a manual review process will be required. This can be achieved through AWS API Gateway + Lambda. I have done similar serverless services before, but I used AWS Step Functions to send email notifications. This time, I plan to try a different method using API Gateway + Lambda.