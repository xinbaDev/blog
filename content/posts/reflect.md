---
title: "对目前工作的一些系统反思"
date: 2022-04-02T20:16:00+11:00
summary: 在IT行业摸爬滚打了好几年了，但是一直没有系统性的反思回顾这些年来的工作。正好趁着公司要扩招之际，一方面准备一些面试的题目，一方面也帮助自己回顾这些年来的工作。这篇文章主要从面试的几个常见问题出发，谈谈我这些年工作的一些总结和想法。
draft: true
---

在IT行业摸怕滚打了好几年了，但是一直没有系统性的反思回顾这些年来的工作。正好趁着公司要扩招之际，一方面准备一些面试的题目，一方面也帮助自己回顾这些年来的工作。这篇文章主要从面试的几个常见问题出发，谈谈我这些年工作的一些总结和想法。

## 业务背景介绍

#### 公司的主要业务（业务逻辑，技术难点）

公司主要業務涉及股票資訊，如股票價格，新聞，相關財報和股東信息，及付費公告翻譯。並以此爲基礎，提供新股增發，基金認購等擴展服務。從業務的邏輯角度講，主要有兩部分。一是從各種數據源抓取各式數據。二是將數據存儲，並高效可靠展示數據給用戶。我個人主要負責後端的應用開發及相關運維，所以我碰到的技術問題和難點也主要集中在這部分。具體來講就是如何高效可靠的將數據及時展現給用戶。

## 架构演进

#### 如何升级架构（服务器，应用，数据库）

我们使用aws作为云服务的提供商。一开始我们就只有两个服务器，一个前端网页服务器，一个后端API服务器。所有的API都集中在一个ec2 instance上面。然后后端服务器连接aws rds来存取数据。随着服务的增多，一个服务器打天下已经行不通了。一是服务增多，服务器不堪重负，响应变慢。二是一旦出问题，整个网站都无法访问，影响面太大。为了降低响应速度，提高可用性，于是不可避免的将服务拆分，将不同的服务分开，正如同把一个很大的function分成许多小function一样。从单机模式逐步变成分布式的模式。

其中比较早期分出去的就是静态文件下载的服务。一开始一些股票的公告都是通过一个nginx的服务器来提供下载服务的，虽然nginx很强大，但是依旧存在单点故障，而且保存的成本较高。后来将公告pdf文件放在aws的s3上，既提高了可靠性和下载速度，同时也降低了储存成本。s3还提供pdf的储存周期，可以将访问频率较少的文件自动迁移到下载速度较慢但是存储成本更便宜的地方，很好的取得性能和成本的平衡。

除了ec2 instance之外，我们还尝试了serverless的服务，将一些相对独立的api迁移到lambda上面，因为了lambda只有在运行才收费的特点，可以大大减少费用，适合那些调用频率不是很高的api。比如验证email是否存在的api，这个功能相对独立，容易被不同的服务调用，但是并不是经常调用，就适合迁移到lambda上。

最后还有一部分服务迁移到了kubernetes的集群上面。kuberbetes是一个非常强大的管理虚拟容器的工具集合。在把服务容器化的基础上，整个服务的部署和管理的体验变得非常的好。服务可以进一步的细分，而且在kubernetes的帮助下，管理起来非常非便。当然随着服务的细分，也给管理提出了挑战，其中一个就是对许许多多的容器的监控。我们之前只有几台服务器的时候，只需要在每一台安装netdata的监控工具就行了，netdata是一个非常开源监控工具，自带了不少监控的项目，如disk, memory, cpu usage等，安装使用简便。但是后来服务器增加后，尤其是上了kubernetes之后，这种方法就不太行了，演进成promethus + grafana + alertmanager的监控栈。

## 对公司底层技术的原理认识

#### 服务器，中间件（缓存，消息队列），数据库， Docker， kubernetes等等

nginx是我最早使用和研究的一个开源服务器程序。之前专门研究过其c的源代码，了解过他大概的代码结构，印象比较深得就是nginx使用了异步响应的模型而不是apache多线程那种模式。除此之外，我对nginx的印象是效能高，可靠，但是扩展起来相对麻烦，需要重新编译。变更设置的时候需要重启，不能够通过api配置。当然这是几年前的版本的，现在应该有不少的扩展和改进了。但是因为nginx是c写的，比较底层的语言，所以可读性没有最近这些年出来的用go写的服务器好读。

数据库这块我使用比较多的是aws提供的rds数据库，其中以postgresql为主。rds将数据库服务化，可以非常轻松的使用其提供的自动备份，master/slave架构，强大的监控等等的服务。还有一点就是aws会提醒数据库安全方面的更新，这一点也是非常有帮助的。aws对数据库有相关的优化，作为使用者，我不需要关注数据库运行所需的硬件，只需要关注设计好db的表, 合理设置index, 比如随着表的增大，需要拆表，包括横拆/竖拆，这方面取决于api访问数据库的模式。还有sql query的优化。这方面我之前有做过相关的研究，比如《记一次对sql的调试和优化(Postgres query planner)》。

redis是我非常喜欢使用的一个缓存中间件。这是一个c语言开发的开源缓存工具，占用系统资源少，但是功能十分强大。支持多种数据结构，而且还在不断的增加。redis可以同时支持上万的连接，而且响应速度很快，在毫秒甚至微秒级别。redis目前我使用的还比较少，主要还是集中在单个instance，并没有用到其集群的功能。虽然redis支持同时多个连接，但是client应用连接时最好使用connectionpool，这样减少建立连接的时间可以大大提高响应速度，还有就是使用指数退避的算法实现timeout重连的方式，减少对redis服务器的压力，这方面也同样使用于db等相关服务。

docker是我使用最多的工具之一。一开始学起来确实比较费力，但是一旦掌握之后就再也离不开了。docker不仅为测试开发提供了很大的方便，比如节省架设本地服务的时间，在不同的环境下只要安装了docker就可以轻松将开发环境架设起来。还有就是容器化后可以很方便的部署，不用担心在本地运行成功但是部署到生产服务器上却不能运行的情况。总之docker极大提高了开发和部署的效率，是devops必不可少的工具之一，

kubernetes则是我最近几年用的比较多的工具。尤其是服务拆分比较多并容器化之后，我使用较多的主要是eks的fargate模式。在fargate模式下，aws将会负责服务器的管理，而不需要我们提前配置好服务器，只需要运行容器的时候，配置所需的cpu, memory就行了，提高了资源的利用率。

promethus+grafana+alertmanager是最近这些年非常受devops欢迎的集群监控工具。因为其开源和强大的社区，其功能强大，易于扩展，甚至许多大公司如cloudflare都在使用。既可以监控基础设施也可以用来监控应用运行情况，非常方便。目前我们kubernetes集群上使用的监控工具就是这个组合。目前最常用到的就是pod运行的情况通知，比如pod的重启通知，或者autoscale的通知。

说到devops就不能不提terraform这个非常好用的工具，使用他可以做到infrastructure as code, 大大降低的了维护的成本。这个工具在某些方面有些类似kubernetes, 也是利用描述性的语言yaml文件来控制infrastucture, 不需要知道怎么实现，只需要按照terraform听得懂得语言描述想要什么结果就行。这个有些像ansible的更高一层抽象。在ansible中你需要写出具体的实现，而在terrafrom中并不需要。

## 系统难点的考察

#### 技术难点 （技术难点，为什么是难点，如何解决），擅长技术的考察

我目前碰到比较有技术难度的应该是两块，一是数据库的升级迁移，二是grapql应用服务的升级优化问题。这两块都是之前工作碰到过，并且思考并纠缠过一段时间的问题。

其中第一个数据迁移的问题主要涉及如何在用户无感的情况下升级迁移。目前我们主要使用postgres数据库，在大版本升级的时候需要关闭一段时间。这段时间大概需要10-20分钟左右，所以要做到用户无感就需要指向新的数据库，但是这里面就有可能会出现数据丢失或不一致的问题。之前的做法是牺牲一部分downtime来换取数据的一致性。具体就是先提前挂维护通告，接下来按照aws的best practice，先暂停对数据库的写，只放行读的操作，不能写但依旧可读，这样可以减少对用户的影响。然后分离master/slave, 将分离出来的slave升级成master，并进行升级。等升级完成后，重新打开对db的写操作，并指向新的升级过的数据库。这样好处是在保证数据consistent的情况下，尽可能减少对用户得影响，也不太容易出错。不过坏处就是过程涉及人工操作比较多，比较繁琐。直到最近看到一个stolon的工具，主打postgres数据库集群可靠性，学习的同时也重新思考这方面的问题。目前的结论就是在proxy上加上重试的功能，只要auto failover的时间在一段时间内，比如20秒，就可以很大程度上解决这个问题。虽然目前还没有实际测试，不过根据我对postgres的使用经验，这个方法应该大概率可行。

第二个问题就是关于graphql服务器应用的升级优化。这个问题其实之前就困扰了我相当长一段时间。最开始是基础设施服务器崩溃，体现在cpu经常超负荷运转，最后不堪重负当机。第一次是升级了机器的配置，问题暂时解决，但是过一段时间，问题又重新出现。这段代码是之前已经离职的同事写的，一开始不了解以为是代码写的不好需要优化。但是认真看了之后发现大部分代码都是自动生成的，代码有问题的话也是框架代码的问题。经过一段时间的测试，对框架渐渐了解，发现一个graphql的query会生成许多sql，而造成cpu飙涨的原因正是因为db抓取那部分。因为db的数据越多，query的数据量就越大，就越吃cpu，响应越慢。当时因为时间关系，没有调查根本的原因，但是很自然就想到使用cache的方式减少对db的query。刚好apllo server有相应的cache plugin，稍微修改用上之后，果然大大降低的cpu的负荷。于是相安无事很长一段时间，甚至一度我都以为问题不会在出现的时候，问题又出现了。虽然没有到当机的地步，当时速度变慢了许多，尤其是cache失效的时候，也开始有些吃不消了。这次我终于下定决心抽出时间，把这个框架比较深入的看了一遍，整个框架是javascript写的，看起来不是很方便。经过许多次实验和对代码的阅读，我终于发现造成服务变慢的根本原因。简单地说就是框架在转换graphql query到sql query的过程中，为了适应性导致一些query效率不高，造成需要抓取许多无用数据的情况，这不仅增加了db的负担，传输的时间，也大大增加了服务器的cpu消耗。知道原因之后，对症下药，对query做了一些限制。这么做虽然有副作用，导致一些query可能不能正常运作，但是经过研究测试并不影响目前现有的query，而且改动的地方很少，容易实现。还有一个最重要的好处是经过改动，之后数据库即使增加资料也不会影响拖慢速度了，可以说是根治这个问题。于是权衡之后使用了这个方法。